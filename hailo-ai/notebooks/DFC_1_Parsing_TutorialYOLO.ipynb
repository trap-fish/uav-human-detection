{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hailo Parsing Examples from TensorFlow/Pytorch to HAR\n",
    "\n",
    "This tutorial describes the steps for parsing models from various frameworks to the HAR format (Hailo Archive).  \n",
    "HAR is a tar.gz archive file that contains the representation of the graph structure and the weights that are deployed to Hailo's runtime.\n",
    "\n",
    "Note:\n",
    "**Running this code in Jupyter notebook is recommended**, see the Introduction tutorial for more details.\n",
    "\n",
    "Note:\n",
    "This section demonstrates the Python APIs for Hailo Parser.\n",
    "You could also use the CLI: try `hailo parser {tf, onnx} --help`.  \n",
    "More details on Dataflow Compiler User Guide / Building Models / Profiler and other command line tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports used throughout the tutorial\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "\n",
    "# import the ClientRunner class from the hailo_sdk_client package\n",
    "from hailo_sdk_client import ClientRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hardware architecture to be used throughout the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_hw_arch = \"hailo8\"\n",
    "# For Hailo-15 devices, use 'hailo15h'\n",
    "# For Mini PCIe modules or Hailo-8R devices, use 'hailo8r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.83-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (1.23.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (3.5.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (1.9.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (2.5.1)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: psutil in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (5.9.4)\n",
      "Requirement already satisfied: py-cpuinfo in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from ultralytics) (1.5.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2022.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.9.24)\n",
      "Requirement already satisfied: filelock in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting triton==3.2.0 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Downloading ultralytics-8.3.83-py3-none-any.whl (922 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m922.2/922.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, torch, seaborn, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "Successfully installed nvidia-cusparselt-cu12-0.6.2 seaborn-0.13.2 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 ultralytics-8.3.83 ultralytics-thop-2.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/hailo/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 30.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.83 ðŸš€ Python-3.10.12 torch-2.6.0+cu124 CPU (12th Gen Intel Core(TM) i7-12700)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim'] not found, attempting AutoUpdate...\n",
      "Collecting onnxslim\n",
      "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: onnx in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from onnxslim) (1.16.0)\n",
      "Requirement already satisfied: sympy in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from onnxslim) (1.13.1)\n",
      "Requirement already satisfied: packaging in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from onnxslim) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from onnx->onnxslim) (1.23.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from onnx->onnxslim) (3.20.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from packaging->onnxslim) (2.4.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /local/workspace/hailo_virtualenv/lib/python3.10/site-packages (from sympy->onnxslim) (1.2.1)\n",
      "Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
      "Installing collected packages: onnxslim\n",
      "Successfully installed onnxslim-0.1.48\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 1.1s, installed 1 package: ['onnxslim']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.9s, saved as 'yolo11n.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (3.2s)\n",
      "Results saved to \u001b[1m/local/workspace/hailo_virtualenv/lib/python3.10/site-packages/hailo_tutorials/notebooks\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n.onnx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "YOLO('yolo11n.pt').export(format='onnx', opset=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Example from ONNX to HAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the ONNX file to be used throughout the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_name = \"yolo11n\"\n",
    "onnx_path = \"../models/yolo11n.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main API of the Dataflow Compiler that the user interacts with is the ClientRunner class (see the API Reference section on the Dataflow Compiler user guide for more information).  \n",
    "\n",
    "Initialize a ClientRunner and use the translate_onnx_model method. \n",
    "\n",
    "Arguments:\n",
    "\n",
    "* model_path\n",
    "* model_name to use\n",
    "* start_node_names (list of str, optional): Name of the first ONNX node to parse.\n",
    "* end_node_names (list of str, optional): List of ONNX nodes, that the parsing can stop after all of them are parsed.\n",
    "* net_input_shapes (dict, optional): A dictionary describing the input shapes for each of the start nodes given in start_node_names, where the keys are the names of the start nodes and the values are their corresponding input shapes. Use only when the original model has dynamic input shapes (described with a wildcard\n",
    "denoting each dynamic axis, e.g. [b, c, h, w]). \n",
    "\n",
    "As a suggestion try translating the ONNX model without supplying the optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Translation started on ONNX model yolo11n\n",
      "[info] Restored ONNX model yolo11n (completion time: 00:00:00.04)\n",
      "[info] Extracted ONNXRuntime meta-data for Hailo model (completion time: 00:00:00.15)\n",
      "[info] NMS structure of yolov8 (or equivalent architecture) was detected.\n",
      "[info] In order to use HailoRT post-processing capabilities, these end node names should be used: /model.23/cv3.0/cv3.0.2/Conv /model.23/cv2.0/cv2.0.2/Conv /model.23/cv3.1/cv3.1.2/Conv /model.23/cv2.1/cv2.1.2/Conv /model.23/cv3.2/cv3.2.2/Conv /model.23/cv2.2/cv2.2.2/Conv.\n",
      "[info] Start nodes mapped from original model: 'images': 'yolo11n/input_layer1'.\n",
      "[info] End nodes mapped from original model: '/model.23/cv3.2/cv3.2.2/Conv', '/model.23/cv2.2/cv2.2.2/Conv', '/model.23/cv2.1/cv2.1.2/Conv', '/model.23/cv3.1/cv3.1.2/Conv', '/model.23/cv2.0/cv2.0.2/Conv', '/model.23/cv3.0/cv3.0.2/Conv'.\n",
      "[info] Translation completed on ONNX model yolo11n (completion time: 00:00:00.73)\n"
     ]
    }
   ],
   "source": [
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_onnx_model(\n",
    "    onnx_path,\n",
    "    onnx_model_name,\n",
    "    start_node_names=[\"/model.0/conv/Conv\"],\n",
    "    end_node_names=[\"/model.23/cv3.2/cv3.2.2/Conv\", \"/model.23/cv2.2/cv2.2.2/Conv\",\n",
    "                   \"/model.23/cv2.1/cv2.1.2/Conv\", \"/model.23/cv3.1/cv3.1.2/Conv\",\n",
    "                   \"/model.23/cv2.0/cv2.0.2/Conv\", \"/model.23/cv3.0/cv3.0.2/Conv\"],\n",
    "    net_input_shapes={\"/model.0/conv/Conv\": [1, 3, 640, 640]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hailo Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hailo Archive is a tar.gz archive file that captures the \"state\" of the model - the files and attributes used in a given stage from parsing to compilation.\n",
    "Use the `save_har` method to save the runner's state in any stage and `load_har` method to load a saved state to an uninitialized runner.\n",
    "\n",
    "The initial HAR file includes:\n",
    "- HN file, which is a JSON-like representation of the graph structure that is deployed to the Hailo hardware.\n",
    "- NPZ file, which includes the weights of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the parsed model in a Hailo Archive file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /local/workspace/hailo_virtualenv/lib/python3.10/site-packages/hailo_tutorials/notebooks/yolo11n_hailo_model.har\n"
     ]
    }
   ],
   "source": [
    "hailo_model_har_name = f\"{onnx_model_name}_hailo_model.har\"\n",
    "runner.save_har(hailo_model_har_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the graph with Hailoâ€™s visualizer tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hailo visualizer {hailo_model_har_name} --no-browser\n",
    "SVG(\"resnet_v1_18.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Example from TensorFlow Lite\n",
    "The Hailo parser supports inference models as inputs, therefore we advise to use TensorFlow Lite representation for TensorFlow 2 models (TF2 SavedModel format is commonly used for training models).  \n",
    "\n",
    "Parsing the TensorFlow Lite format is similar to parsing ONNX models.  \n",
    "The parser identifies the input format automatically.\n",
    "\n",
    "The following example shows how to parse a TensorFlow Lite model, using a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"dense_example\"\n",
    "model_path = \"../models/v3-large-minimalistic_224_1.0_float.tflite\"\n",
    "\n",
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_tf_model(model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Conversion Methods from Tensorflow to Tensorflow Lite\n",
    "The following examples focus on Tensorflow's TFLite converter support for various TF formats, showing\n",
    "how older formats of TF can be converted to TFLite, which can then be used in Hailo's parsing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple Keras model and convert it to tflite\n",
    "\n",
    "# Building a simple Keras model\n",
    "def build_small_example_net():\n",
    "    inputs = tf.keras.Input(shape=(24, 24, 96), name=\"img\")\n",
    "    x = tf.keras.layers.Conv2D(24, 1, name=\"conv1\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.9, name=\"bn1\")(x)\n",
    "    outputs = tf.keras.layers.ReLU(max_value=6.0, name=\"relu1\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"small_example_net\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Converting the Model to tflite\n",
    "model = build_small_example_net()\n",
    "model_name = \"small_example\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()  # may cause warnings in jupyter notebook, don't worry.\n",
    "tflite_model_path = \"../models/small_example.tflite\"\n",
    "with tf.io.gfile.GFile(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Parsing the model to Hailo format\n",
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_tf_model(tflite_model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, convert an already saved SavedModel to tflite\n",
    "model_path = \"../models/dense_example_tf2/\"\n",
    "model_name = \"dense_example_tf2\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()  # may cause warnings in jupyter notebook, don't worry.\n",
    "tflite_model_path = \"../models/dense_example_tf2.tflite\"\n",
    "with tf.io.gfile.GFile(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Parsing the model to Hailo format\n",
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_tf_model(tflite_model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third option, convert h5 file to tflite.\n",
    "model_path = \"../models/ew_sub_v0.h5\"\n",
    "model_name = \"ew_sub_example\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_path = \"../models/ew_sub_example.tflite\"\n",
    "with tf.io.gfile.GFile(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Parsing the model to Hailo format\n",
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_tf_model(tflite_model_path, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
